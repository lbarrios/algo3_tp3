
% Búsqueda local

% Explicación inicial

% Solución inicial
Partimos desde una solución factible obtenida a partir de un algoritmo goloso. En caso de que el algoritmo anterior no devuelva una solución factible, corremos Dijkstra utilizando la sumatoria de los pesos $\omega_1$ como función objetivo. Si Dijkstra tampoco devuelve una solución factible, podemos asegurar que no existe solución al problema\footnote{Demostrado en la sección de heurística golosa}. En este caso, devolvemos ``no''.

Solución Inicial 2:
Corro dijkstra con omega1 y omega2, formando $c_1$ y $c_2$. Tomo el conjunto $U$ de nodos formados por $c_1 \cap c_2$. Para cada par de nodos $n_1,n_2$ adyacentes, me fijo si puedo formar un camino mejor valuado en $\omega_2$ reemplazando el camino $c^1_{n_1,n_2}$ por $c^2_{n_1,n_2}$, siempre que el nuevo camino no se pase de K al valuarlo en $\omega_2$. La evaluación se hace ordenando por omega2, de forma tal que el camino obtenido sea el que minimice la misma en comparación con el resto de los posibles caminos que se podrían obtener con este método.

\begin{comment}

% Definición de vecindad
Vecindad <<A>>: 

Dado el grafo inicial G, y una solución formada por un camino $c \in G$, definimos sus soluciones vecinas como aquellas resultantes de tomar un subcamino $d_{n_1,n_2} \in c$ entre dos pares de nodos $n_1,n_2$ cualesquiera, y reemplazarlo por un camino ``mejor'' $d_{n_1,n_2}^* \in G$, de tal forma que el camino $c^* = c - d_{n_1,n_2} + d_{n_1,n_2}^*$ resultante cumpla: 
\begin{list}
\item $\omega_1(c^*) \leq k $
\item $\omega_2(c^*) < \omega_2(c)$
\end{list}

Dada una solución $S$ formada por un camino $c$ definimos su vecindad como el conjunto $S^*$ de todos los caminos $c^*$ posibles.

% Selección de vecino
Dada una vecindad $S^*$, se probaron los siguientes métodos de elegir al vecino:
\begin{list}
	\item Steepest descent, con $\omega_2$ como función objetivo.
	\item Steepest descent, con $\omega_1*\omega_2$ como función objetivo.
	\item Elegir el primero que se encuentre.
	\item Stochastic \fixme{completar} eligiendo el vecino de forma pseudoaleatoria.
\end{list}

\end{comment}

% Familias malas
Familias malas

Si elegimos como solución inicial a las heurísticas Greedy B o C desarrolladas en la sección previa, se ha expuesto que pueden fallar en el
intento de dar una solución factible, aún existiendo una. El Greedy A siempre encuentra una solución factible de existir ésta. Veamos que
tomándola como solución inicial, nuestra heurística de búsqueda local puede quedar arbitrariamente lejos de la solución óptima.

Presentamos la siguiente familia de grafos.

\ponerGrafico{imagenes/maloLocalA.png}{}{0.5}{malo-para-local-a}

Para ir de 1 a 5 hay tres caminos posibles: ($C_1$) $1 \rightarrow 2 \rightarrow 5$; ($C_2$) $1 \rightarrow 3 \rightarrow 5$;
($C_3$) $1 \rightarrow 4 \rightarrow 5$;

\begin{eqnarray}
 \omega_1(C_1) &=& 4	\\ 
 \omega_2(C_1) &=& 2	\\
 \omega_1(C_2) &=& 2	\\
 \omega_2(C_2) &=& 2x   \\
 \omega_1(C_3) &=& 6	\\
 \omega_2(C_3) &=& 1
\end{eqnarray}

Supongamos que K vale 4.
Como decíamos, partimos del camino mínimo entre $u$ y $v$ de acuerdo a $\omega_1$, $C_2$. El algoritmo va a intentar intercambiar $C_2$ por
$C_3$, el camino que minimiza $\omega_2$. Sin embargo, como éste se pasa del límite K, el algoritmo no puede seguir y devuelve $C_2$. Sin
embargo $C_1$ era una solución mejor.

$\frac{\omega_2(C_2)}{\omega_2(C_1)} = x$.

Haciendo crecer el valor de $x$ podemos encontrar grafos en los que nuestro algoritmo devuelve una
solución arbitrariamente lejos de la óptima.
