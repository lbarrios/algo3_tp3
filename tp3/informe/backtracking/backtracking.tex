\subsubsection{Descripción}

El algoritmo a cada paso tiene un camino $P = [v_1 = u, \dots, v_{i-1}]$ e intenta agregar al camino un nuevo nodo $v_i$ de la adyacencia de $v_{i-1}$, hasta que llega al nodo destino $V$. De esta forma recorre todos los caminos entre $U$ y $V$. De entre todos los caminos tales que el peso por $\omega_1$ es menor o igual a K, se guarda el de menor $\omega_2$.

Se implementaron las siguientes podas:

\begin{itemize}
    \item Se exploran solamente caminos simples. Si un camino tiene ciclos, removiéndolo se obtiene uno con menor longitud tanto en $\omega_1$ como en $\omega_2$. Por lo tanto la solución que buscamos no puede tener ciclos, y nos restringimos a caminos simples. La poda se implementó guardando un arreglo que marca para cada nodo si es parte del camino o no. No se agrega nuevamente si ya es parte del camino.
    \item Si el camino parcial $P = [v_1 = u, \dots, v_{i-1}]$ cumple:

        $omega_1(P)$, sumado a la distancia según $\omega_1$ entre $v_{i-1}$ y $V$, es mayor que $K$

entonces se abandona la rama, es decir, no se recorren los caminos que empiezan en $P$, ya que cualquiera de éstos no va a cumplir con la restricción de que $omega_1$ sea menor o igual a $K$.
    \item Si el camino parcial $P = [v_1 = u, \dots, v_{i-1}]$ cumple:

        $omega_2(P)$, sumado a la distancia según $\omega_2$ entre $v_{i-1}$ y $V$, es mayor o igual que el peso según $\omega_2$ del mejor camino encontrado hasta el momento

entonces se abandona la rama, es decir, no se recorren los caminos que empiezan en $P$, ya que cualquiera de éstos no va a proporcionar una solución mejor que la ya encontrada.
\end{itemize}

Para saber las distancias entre todos los vértices y $v$, al principio se corre dos veces Dijkstra, utilizando como peso primero $\omega_1$ y luego $\omega_2$.

A continuaci\'on, el pseudoc\'odigo de la funci\'on \texttt{backtrack}.

\begin{algorithm}[H]
    \caption{\texttt{backtrack}(Edge e)}
\begin{algorithmic}[1]
  \State Node n $\leftarrow$ e.toNode
  \State currentBranch.path.push\_back(n)
  \State currentBranch.totalOmega1 += e.omega1
  \State currentBranch.totalOmega2 += e.omega2
  \State visited[n] $\leftarrow$ true
  \State podar $\leftarrow$ currentBranch.totalOmega1 + distanceToVOmega1[n] $>$ K \textbf{or} currentBranch.totalOmega2 + distanceToVOmega2[n] $\geq$ bestSolutionFound.totalOmega2
  \If{\textbf{not} podar}
  \If{n = V}
      \State bestSolutionFound $\leftarrow$ currentBranch
  \Else{}
      \For{\textbf{each} Node a \textbf{in} adjacencyList[n] }
	\If{\textbf{not} visited[a] }
          \State Edge f = incidencyMatrix[n][a]
          \State backtrack(f)
	\EndIf
      \EndFor
  \EndIf
  \EndIf
  \State currentBranch.path.pop\_back()
  \State currentBranch.totalOmega1 -= e.omega1
  \State currentBranch.totalOmega2 -= e.omega2
  \State visited[n] $\leftarrow$ false
\end{algorithmic}
\end{algorithm}

\subsubsection{Complejidad}

Utilizamos una implementación de Dijkstra sobre heap, cuya complejidad es $O(m \times log(n))$. Como lo corremos 2 = $O(1)$ veces, la complejidad es $O(m \times log(n))$. La complejidad principal del algoritmo está dada por la función \texttt{backtrack}, que procedemos a analizar.

Sea $x$ la cantidad de nodos no visitados, es decir la cantidad de nodos que no están en el camino parcial de $u$ a $v$. Sea $T(x)$ la cantidad de operaciones que realiza la función \texttt{backtrack} cuando la cantidad de nodos no visitados es $x$. Sea $N$ la cantidad de nodos del grafo. Se propone la siguiente relación:
\[
    T(x) \leq x T(x-1) + O(N)
\]
La cantidad de llamadas a \texttt{backtrack} que se hacen es a lo sumo $x$, que son los nodos no marcados como visitados, y en esas llamadas la cantidad de nodos marcados no visitados disminuye en uno ya que se marca como visitado al nodo $n$. $n$ no estaba marcado previamente pues entonces no se hubiése llamado a la función con la arista incidente a él.

Además de las llamadas recursivas se ejecuta un ciclo con una cantidad de iteraciones igual al tamaño de la adyacencia de $n$. La adyacencia es a lo sumo $N$, la cantidad de nodos del grafo. Todas las operaciones que restan: accesos aleatorios a arreglos, sumas, son $O(1)$.

Veamos que $T(x) \in O((x+1)!)$, es decir
\[
    T(x) \leq c(x+1)!
\]
para una constante $c$ y para todo $x \geq x_0$. Por inducción en $x$:
\begin{itemize}
    \item Caso base: $x=1$
        Si se llama a \texttt{backtrack} con un solo nodo no visitado, este es $n$, y no quedan nodos para llamar recursivamente. Luego la cantidad de operaciones es $N$.
        \[
            N \leq c \times 2! \Leftrightarrow N \leq N \times 2!
        \]
        que es verdadero, tomando $c = N$ y $x_0 = 1$.
    \item Paso inductivo: Supongo $T(x-1) \leq cx!$, quiero ver que $T(x) \leq c(x+1)!$
        \[
            T(x) \leq x T(x-1) + O(N) \leq_{paso inductivo} x \times c \times x! + N
        \]
        \[
            c \times x \times x! + N \leq c \times (x+1)! \Leftrightarrow N \leq c \times (x+1) \times x! - c \times x \times x! \Leftrightarrow N \leq c \times x!
        \]
        que es válido para los valores que elegimos de $c$ y $x_0$.
\end{itemize}

El valor que nos interesa es $T(N)$, que es $O((N+1)!)$. La complejidad final es $O(m \times log(N)) + O((N+1)!) = O((N+1)!)$.

\newpage
\subsubsection{Experimentación}

Se efectuó una experimentación sobre el tiempo de ejecución del algoritmo. Primero se evaluó sobre instancias \textit{aleatorias}, de distinto tamaño de entrada. Se obtuvieron dos conclusiones importantes.

Primero, la curva que se puede observar representa una función que crece cada vez más rápido, es decir que no es lineal. Al mismo tiempo, no parece crecer tan rápido como la función factorial que expresa la complejidad teórica del algoritmo.

Segundo, hay mucha amplitud de valores para tamaños de entrada similares. Esto puede deberse a la naturaleza aleatoria de la instancia. Los nodos de origen y destino pueden estar muy cerca o muy lejos, puede haber muchos o pocos caminos entre ellos.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=\textwidth]{imagenes/backtracking-complejidad-random.pdf}
        \caption{Tiempo de ejecución de \texttt{backtracking} en instancias \textit{aleatorias}}
    \end{center}
\end{figure}

\newpage
A continuación evaluamos el comportamiento del algoritmo frente a instancias \textit{mágicas}. Se notaron grandes diferencias con la experimentación anterior.

Como primera impresión, se puede observar una curva que parece ser la característica de las funciones factoriales. Los tiempos de ejecución fueron mucho mayores que frente a instancias \textit{aleatorias}. Para los mismos tamaños de entrada, en las últimas no se llegó a tiempos de 1 milisegundo, mientras que en las primeras se superó ampliamente el segundo.

La explicación que se encuentra, según lo desarrollado en la sección de \textit{Generación de instancias}, es que las instancias \textit{mágicas} proveen una gran cantidad de caminos entre $u$ y $v$ que son candidatos a ser el óptimo. Mientras que las instancias \textit{aleatorias} no garantizan ni la lejanía de $u$ y $v$ ni una gran cantidad de caminos candidatos a ser el óptimo. Probablemente una vez que se encuentre el camino las otras ramas de solución se puedan descartar rápidamete.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=\textwidth]{imagenes/backtracking-complejidad-general.pdf}
        \caption{Tiempo de ejecución de \texttt{backtracking} en instancias \textit{mágicas}}
    \end{center}
\end{figure}

\newpage
Se quiso investigar la performance del algoritmo en relación a $n$, la cantidad de nodos.

Para ello se generaron instancias \textit{mágicas} de distintos valores de $n$, y con $m$ fijo en la mitad de las aristas posibles, es decir $\frac{n(n-1)}{4}$.

Para ver la magnitud de los valores fue apropiada una escala logarítmica. Se puede percibir una muy ligera concavidad positiva de la curva, lo que vendría a indicar que la función crece más rápido que una exponencial(en escala logarítmica toda recta con pendiente $m$ representa la función $m^x$). Con estos resultados se añade evidencia al cálculo de complejidad efectuado, que indica una complejidad factorial en función de $n$.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=\textwidth]{imagenes/backtracking-complejidad-funcion-de-n.pdf}
        \caption{Tiempo de ejecución de \texttt{backtracking} en instancias \textit{mágicas}, en función de \textit{n}}
    \end{center}
\end{figure}

\newpage
A continuación se exploró el comportamiento del algoritmo en función de $m$, la cantidad de aristas. El valor de $n$ estuvo fijo en 25 y la cantidad de aristas se varió entre $n-1$ y la máxima cantidad para un grafo de 25 vertices.

Nuevamente con escala logarítmica, se observó un gran crecimiento en el tiempo de ejecución a medida que se aumenta $m$. Ésto era predecible ya que se aumenta el tamaño de la adyacencia de los vértices y por lo tanto la cantidad de iteraciones del ciclo en el algoritmo. A más alto nivel, la cantidad de caminos entre $u$ y $v$ tiende a aumentar. Sin embargo, la curva observada tiene concavidad negativa, por lo que representa a una función que crece más lento que una exponencial.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=\textwidth]{imagenes/backtracking-complejidad-funcion-de-m.pdf}
        \caption{Tiempo de ejecución de \texttt{backtracking} en instancias \textit{mágicas}, en función de \textit{m}}
    \end{center}
\end{figure}
